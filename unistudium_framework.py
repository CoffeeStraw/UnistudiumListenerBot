"""
Functions to talk with Unistudium
"""
import requests
import re
from colorama import Fore, Style

import utility as uti
from settings import type_to_sym, LOGIN_URL, MAIN_URL


def reconnect(user_data):
    """
    Attempt to perform a login to the Unistudium website, saving the cookies in user_data.

    Returns:
        "OK" if the login was performed correctly, else a description with the error that can be used to inform the users.
    """
    # Check if user's session exists
    if 'session' not in user_data:
        user_data['session'] = requests.Session()

    # Getting credentials if available
    try:
        payload = {
            "username": user_data['credentials']['username'],
            "password": user_data['credentials']['password']
        }
    except KeyError:
        return "Non hai effettuato ancora il login, effettualo tramite il comando /login."

    # Check if server is alive
    status_code = requests.head(LOGIN_URL).status_code
    if status_code != 200:
        print(Fore.RED + "[CONNECTION] Server irraggiungibile. Status code: " + str(status_code))
        return "Non riesco a contattare il server (CODE: %d), riprova piÃ¹ tardi..." % status_code

    # Check if the login is still valid (without performing a login)
    if user_data['session'].head(MAIN_URL).status_code == 200:
        return "OK"

    # Perform the login
    if user_data['session'].post(LOGIN_URL, data=payload).url != MAIN_URL:
        return "Le credenziali fornite non sono valide. Riprova."
    return "OK"


def get_course_ID(course_url):
    """
    Returns the ID of a given course's url.
    """
    pattern = r"id=(.+)"
    return re.search(pattern, course_url).group(1)


def get_courseslist(user_data):
    """
    Attempt to get a list of courses from Unistudium MAIN_URL (view settings.py) page, using the session in variable user_data (with login performed).

    The courses are returned in a dictionary indicized by the course name containing another dictionary with the urls, like:
    {'COURSE NAME': {'url': Course url', 'forum_url': Course forum url'}}
    """
    # Get source code of the main_url page
    main_page = user_data['session'].get(MAIN_URL)

    # Extract the content of some particular h3 tags containing the courses' name and link
    pattern = r"<h3 class=\"coursename\">(.+?)</h3>"
    courses_html = re.findall(pattern, str(main_page.content))

    # Compiling regex
    pattern_name = re.compile(r"<\w+.*?>(.+?)<\/a>")
    pattern_url = re.compile(r"href=\"(.+?)\"")

    # Extract and save informations in a dict object
    courses = {}
    for course_html in courses_html:
        name = pattern_name.search(course_html).group(1).strip()
        url = pattern_url.search(course_html).group(1).strip()
        forum_url = get_forum_url(user_data['session'], url).strip()

        courses[name] = {'followed': 'ðŸ””', 'url': url, 'forum_url': forum_url}

    return courses


def get_course_fileslist(user_data, course_url):
    """
    Attempt to get a list with all the files in a course's page, grouped by sections.

    The returned list is constructed as follow:
    [ ['Section Name', ['Type of File', 'Name of the File', 'URL of the File']], [...] ]
    """
    # Get source code of the course_url page
    course_page = user_data['session'].get(course_url)

    # Extract the content from some particular html tags in the course page, retrieving the sections
    pattern = r"<li id=\"section-[0-9]+\"(.+?)<\/ul><\/div><\/li>"
    sections = re.findall(pattern, str(course_page.content))

    # Compiling regex
    pattern_section = re.compile(r"<h3 class=\"sectionname\"><span>(.+?)</span></h3>")
    pattern_files = re.compile(r"<div class=\"activityinstance\">(.+?)<\/div>")
    pattern_file_link = re.compile(r"<a class=\"\" onclick=\".*\" href=\"(.+?)\"")
    pattern_file_name_type = re.compile(r"<span class=\"instancename\">(.+?)<span class=\"accesshide \" ?>(.+?)</span>")

    files_list = []
    for i, section in enumerate(sections):
        # Section name
        section_name = pattern_section.search(section)
        if section_name:
            section_name = section_name.group(1)
        else:
            section_name = "Argomento 0"
        files_list.append([section_name, []])

        # Files in the section
        files_html = pattern_files.findall(section)

        for file_html in files_html:
            try:
                file_link = pattern_file_link.search(file_html).group(1).strip()
                file_name, file_type = pattern_file_name_type.search(file_html).group(1, 2)
                file_name = uti.text_to_utf8(file_name.strip())
                file_type = file_type.strip()

                files_list[i][1].append([file_type, file_name, file_link])
            except AttributeError:
                pass

    return files_list


def get_formatted_fileslist(files_list, custom_mex=""):
    """
    Returns a list of formatted message generated by the list of sections of files given.
    It is returned a list, since messages could exceed the maximum length allowed by Telegram (4096 chars atm of writing).

    Parameters:
        files_list (list): List of sections of files returned by get_course_fileslist()        
        custom_mex (str): A message to put at the beginning of the first message of the list
    """
    i = 0
    mexs = [custom_mex]

    for sec in files_list:
        sec_string = "Nella sezione *%s*" % sec[0] + "\n"
        if len(mexs[i] + sec_string) > 4096:  # Max length of text allowed by Telegram
            i += 1
            mexs.append("")
        mexs[i] += sec_string

        for file_downloaded in sec[1]:
            if file_downloaded[0] not in type_to_sym:
                print(Fore.RED + "[ERROR] Risolvere eccezione simbolo: " + file_downloaded[0])
                type_to_sym[file_downloaded[0]] = "â‰ï¸"

            file_string = type_to_sym[file_downloaded[0]] + " [" + file_downloaded[1] + "](" + file_downloaded[2] + ")\n"
            if len(mexs[i] + file_string) > 4096:
                i += 1
                mexs.append("")
            mexs[i] += file_string

        mexs[i] += "\n"

    return mexs


def get_forum_url(current_session, course_url_link):
    """
    Get the forum news url, given the course link. It uses current_session with the cookies obtained by performing the login.
    """
    # Get source code of the course_url page
    course_page = current_session.get(course_url_link)
    
    # Extracting url of the forum from the course page
    pattern = r"<a class=\"\" onclick=\"\" href=\"(.+?)\"><img src"
    try:
        return re.search(pattern, str(course_page.content)).group(1)
    except AttributeError:
        return "https://www.unistudium.unipg.it/unistudium/error/"


def get_forum_news(user_data, forum_link_url):
    """
    Attempt to get a list of all the forum news from a course forum url

    Returned list will contain the news as follow:
    [ ["News name", "URL"], [...] ]
    """
    # Get source code of the forum_url page
    course_page_content = user_data['session'].get(forum_link_url).content
    
    # Extract the content from some particular html tags in the course page, retrieving the sections
    pattern = r"<tr class=(.+?)<\/tr>"
    news_msg = re.findall(pattern, str(course_page_content))

    # Compiling regex
    pattern_news = re.compile(r"<td class=\"topic starter\"><a href=\"(.*?)\">(.*?)</a>.*</td>")

    # Extract news name and url
    news = {}
    for new_news in news_msg:
        try:
            url, name = pattern_news.search(new_news).group(1,2)
        except AttributeError:
            return []

        name = uti.text_to_utf8(name)
        news[name] = url

    return news


def get_news_msg(user_data, link_news):
    """
    Access to a news from url given and returns the content of the news
    """
    # Get source code of the forum_url page
    news_content = user_data['session'].get(link_news).content

    pattern = r"<div class=\"author\".+?</div>"
    head = re.search(pattern, str(news_content)).group(0)

    pattern = r">(.+?)<"
    head = re.findall(pattern, head)

    author = head[1].title()
    date = uti.text_to_utf8(head[2].replace(" - ", "")).title()

    pattern = r"<div class=\"posting fullpost\".+?>(.+?)<div class=\"attachedimages\""
    news_msg = uti.text_to_utf8(re.search(pattern, str(news_content)).group(1))

    news_msg = re.sub(r"<br */? *>", "\n", news_msg).replace("</p>", "\n").replace("</div>", "\n")
    news_msg = re.sub(r"<.*?>", "", news_msg)

    final_mex = ""\
                "ðŸ‘¤ AUTORE: {}\n"\
                "ðŸ“† DATA: {}\n\n"\
                "ðŸ“ƒ MESSAGGIO:\n"\
                "{}".format(author, date, news_msg)

    return final_mex
